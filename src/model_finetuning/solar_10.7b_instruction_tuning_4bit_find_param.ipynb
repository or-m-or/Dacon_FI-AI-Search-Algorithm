{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7d0aa1-9423-4049-a786-24b74655d737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U transformers\n",
    "!pip3 install -q -U datasets\n",
    "!pip3 install -q -U bitsandbytes\n",
    "!pip3 install -q -U peft\n",
    "!pip3 install -q -U trl\n",
    "!pip3 install -q -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28efaf0-ac99-47c5-bc68-8ce61dd374c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q -U optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6023567d-573d-4c23-8af5-3b557d2ebfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline, TrainingArguments\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8d8cd1-f491-42fd-8239-a1bb713f4b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ba421e0629464c86eaef3aeb0fab33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca35b178-f930-4336-8d03-c5d4e62a9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f16b4b-af46-47d7-bfc6-ff3d3ec39d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'output'],\n",
       "        num_rows: 496\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ade5b57-95f1-48f3-8c91-8c22ae54d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset, train eval로 나눔 0.9:0.1\n",
    "\n",
    "split_datasets = dataset['train'].train_test_split(test_size=0.1)\n",
    "\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2727442-ca97-4324-a426-bdf5991f2ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 446\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "543c4943-cd65-4464-a8c1-ff455e71361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2e8487-d79f-45ac-bc0f-cd1d7e77630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4비트 양자화\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddcbf5fe-f21e-4759-be0a-907b16c06b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fc2ae722fb41d9b87779342b2ec5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "token = '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'\n",
    "\n",
    "BASE_MODEL = \"upstage/SOLAR-10.7B-Instruct-v1.0\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL, use_auth_token=token, device_map=\"auto\", quantization_config=bnb_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, use_auth_token=token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea1c21a-f98e-41a7-b91d-38defc7d6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 gpu사용 accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model = accelerator.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10be0ab-9f52-4aac-b0b7-f6eedc7a2c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(example):\n",
    "    output_texts = []\n",
    "    for i in range(len(example['instruction'])):\n",
    "        prompt = f\"### Instruction: {example['instruction'][i]}\\n\\n### Response: {example['output'][i]}<eos>\"\n",
    "        output_texts.append(prompt)\n",
    "    return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e371d71-190e-4e8a-bd7c-7bdc2f57a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_lora_dropout(trial):\n",
    "    dropout = trial.suggest_uniform('lora_dropout', 0.05, 0.1)\n",
    "    return round(dropout, 2)  # dropout 소수점 이하 두 자리로 반올림 > 안됨 이유를 모름\n",
    "\n",
    "def suggest_learning_rate(trial):\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-4, 2e-3)\n",
    "    return round(lr, 4) # learning_rate 소수점 이하 네 자리로 반올림 > 안됨 이유를 모름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d990b9a-e90f-4272-b51b-3360017f8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # lora 하이퍼파라미터 검색 공간 정의\n",
    "    r = trial.suggest_categorical('lora_r', [6, 8, 16, 32])\n",
    "    lora_alpha = trial.suggest_categorical('lora_alpha', [4, 8, 16])\n",
    "    lora_dropout = suggest_lora_dropout(trial)\n",
    "    \n",
    "    # args 하이퍼파라미터 검색 공간 정의\n",
    "    learning_rate = suggest_learning_rate(trial)\n",
    "    per_device_train_batch_size = trial.suggest_categorical('per_device_train_batch_size', [1, 2, 4])\n",
    "    warmup_steps = trial.suggest_int('warmup_steps', 500, 2000) // 100 * 100\n",
    "\n",
    "    # lora 설정\n",
    "    lora_config = LoraConfig(\n",
    "    r=r,\n",
    "    lora_alpha = lora_alpha,\n",
    "    lora_dropout = lora_dropout,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "    \n",
    "    # TrainingArguments 설정\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"outputs\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        max_steps=3000,\n",
    "        gradient_accumulation_steps=4,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        warmup_steps=warmup_steps,\n",
    "        fp16=True,\n",
    "        logging_steps=100,\n",
    "        push_to_hub=True,\n",
    "        report_to='none',\n",
    "    )\n",
    "\n",
    "    # Trainer 초기화\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        max_seq_length=512,\n",
    "        peft_config=lora_config,\n",
    "        formatting_func=generate_prompt,\n",
    "    )\n",
    "\n",
    "    # 다중 gpu사용 accelerator\n",
    "    trainer = accelerator.prepare(trainer)\n",
    "    \n",
    "    # 모델 학습\n",
    "    trainer.train()\n",
    "\n",
    "    # 평가 및 메트릭 반환\n",
    "    eval_results = trainer.evaluate()\n",
    "    eval_loss = eval_results['eval_loss']  # 손실이 최소화되는 것이 목표\n",
    "\n",
    "    # 하이퍼파라미터와 결과를 JSON 파일로 저장\n",
    "    result = {\n",
    "        'trial_number': trial.number,\n",
    "        'params': trial.params,\n",
    "        'eval_loss': eval_loss\n",
    "    }\n",
    "\n",
    "    # JSON 파일 경로\n",
    "    file_path = 'optuna_results.json'\n",
    "\n",
    "    # 파일이 이미 존재하는 경우 기존 데이터 읽기\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            with open(file_path, 'r') as f:\n",
    "                all_results = json.load(f)\n",
    "        except json.JSONDecodeError:\n",
    "            # JSONDecodeError가 발생하면 빈 리스트로 초기화\n",
    "            all_results = []\n",
    "    else:\n",
    "        all_results = []\n",
    "\n",
    "    # 결과 추가\n",
    "    all_results.append(result)\n",
    "\n",
    "    # 결과를 JSON 파일에 저장\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(all_results, f, indent=4)\n",
    "\n",
    "    return eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c527aba-f86c-46b5-939b-3642c55c4f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 04:21:15,375] A new study created in memory with name: no-name-3ff185a1-4c3f-4e79-a561-b9aa94289a70\n",
      "/tmp/ipykernel_1044/2697971246.py:2: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout = trial.suggest_uniform('lora_dropout', 0.05, 0.1)\n",
      "/tmp/ipykernel_1044/2697971246.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('learning_rate', 1e-4, 2e-3)\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:280: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce746fa4d1b443338216754316c47dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:408: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 2:09:39, Epoch 53/55]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.342700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.211600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.162600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.141100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.125100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.079500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.064800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.057400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.053800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.049700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-20 06:31:16,987] Trial 0 finished with value: 1.582659125328064 and parameters: {'lora_r': 16, 'lora_alpha': 4, 'lora_dropout': 0.05092235181386536, 'learning_rate': 0.00015923015358428508, 'per_device_train_batch_size': 2, 'warmup_steps': 798}. Best is trial 0 with value: 1.582659125328064.\n"
     ]
    }
   ],
   "source": [
    "# Optuna Study 생성\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d1eebcc-4f47-4633-998f-ceea20f8b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    'trial_number': 123,\n",
    "    'params': 333312312,\n",
    "    'eval_loss': 123123\n",
    "}\n",
    "\n",
    "# JSON 파일 경로\n",
    "file_path = 'optuna_results.json'\n",
    "\n",
    "# 파일이 이미 존재하는 경우 기존 데이터 읽기\n",
    "if os.path.exists(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    except json.JSONDecodeError:\n",
    "        # JSONDecodeError가 발생하면 빈 리스트로 초기화\n",
    "        all_results = []\n",
    "else:\n",
    "    all_results = []\n",
    "\n",
    "# 결과 추가\n",
    "all_results.append(result)\n",
    "\n",
    "# 결과를 JSON 파일에 저장\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(all_results, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
