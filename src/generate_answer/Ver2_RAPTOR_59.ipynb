{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ì¬ì •ì •ë³´ AI ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ê²½ì§„ëŒ€íšŒ - RAG, RAPTOR ì ìš©**\n",
    "> **RAG, RAPTOR ì ìš©, No Finetuning**\n",
    "\n",
    "ë³¸ ëŒ€íšŒì˜ ê³¼ì œëŠ” ì¤‘ì•™ì •ë¶€ ì¬ì • ì •ë³´ì— ëŒ€í•œ **ê²€ìƒ‰ ê¸°ëŠ¥**ì„ ê°œì„ í•˜ê³  í™œìš©ë„ë¥¼ ë†’ì´ëŠ” ì§ˆì˜ì‘ë‹µ ì•Œê³ ë¦¬ì¦˜ì„ ê°œë°œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. <br>ì´ë¥¼ í†µí•´ ë°©ëŒ€í•œ ì¬ì • ë°ì´í„°ë¥¼ ì¼ë°˜ êµ­ë¯¼ê³¼ ì „ë¬¸ê°€ ëª¨ë‘ê°€ ì‰½ê²Œ ì ‘ê·¼í•˜ê³  í™œìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. <br><br>\n",
    "ë² ì´ìŠ¤ë¼ì¸ì—ì„œëŠ” í‰ê°€ ë°ì´í„°ì…‹ë§Œì„ í™œìš©í•˜ì—¬ source pdf ë§ˆë‹¤ Vector DBë¥¼ êµ¬ì¶•í•œ ë’¤ langchain ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ llama-2-ko-7b ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ RAG í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ì¶”ë¡ í•˜ëŠ” ê³¼ì •ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. <br>( train_setì„ í™œìš©í•œ í›ˆë ¨ ê³¼ì •ì€ í¬í•¨í•˜ì§€ ì•Šìœ¼ë©°, test_set  ì— ëŒ€í•œ ì¶”ë¡ ë§Œ ì§„í–‰í•©ë‹ˆë‹¤. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ğŸ’¡ **NOTE**: ì´ ì˜ˆì œì—ì„œ ì‚¬ìš©í•œ ëª¨ë¸ ë° ë²¡í„° DB \n",
    "\n",
    "1. LLM : [rtzr/ko-gemma-2-9b-it](https://huggingface.co/rtzr/ko-gemma-2-9b-it)\n",
    "2. Embed Model : [intfloat/multilingual-e5-base](https://huggingface.co/intfloat/multilingual-e5-base)\n",
    "3. Vector DB : FAISS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.0)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate)\n",
      "  Downloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.21.0->accelerate)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m417.5/417.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m435.5/435.5 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, huggingface-hub, accelerate\n",
      "Successfully installed accelerate-0.33.0 huggingface-hub-0.24.5 safetensors-0.4.4 tqdm-4.66.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers[torch]\n",
      "  Downloading transformers-4.44.0-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.4)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers[torch])\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.33.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
      "Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.44.0-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.7.24 tokenizers-0.19.1 transformers-4.44.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.3)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.3.5-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.3.5-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, requests, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "Successfully installed aiohappyeyeballs-2.3.5 aiohttp-3.10.3 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.20.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-17.0.0 pyarrow-hotfix-0.6 pytz-2024.1 requests-2.32.3 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.2.13-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Collecting langchain-core<0.3.0,>=0.2.30 (from langchain)\n",
      "  Downloading langchain_core-0.2.30-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.99-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.3)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.30->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (4.9.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain) (2.4)\n",
      "Downloading langchain-0.2.13-py3-none-any.whl (997 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.30-py3-none-any.whl (384 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m384.8/384.8 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.99-py3-none-any.whl (140 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, pydantic-core, orjson, jsonpatch, greenlet, annotated-types, SQLAlchemy, pydantic, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed SQLAlchemy-2.0.32 annotated-types-0.7.0 greenlet-3.0.3 jsonpatch-1.33 langchain-0.2.13 langchain-core-0.2.30 langchain-text-splitters-0.2.2 langsmith-0.1.99 orjson-3.10.7 pydantic-2.8.2 pydantic-core-2.20.1 tenacity-8.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (23.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.3)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.32.0.20240712-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
      "Downloading types_requests-2.32.0.20240712-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.21 types-requests-2.32.0.20240712\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.13)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.30)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.99)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.12 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.29 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.30)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
      "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (0.1.99)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.26.0)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
      "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<0.3.0,>=0.2.29->langchain-openai)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.29->langchain-openai) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.0)\n",
      "Downloading langchain_openai-0.1.21-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, jiter, tiktoken, openai, langchain-openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.9.0\n",
      "    Uninstalling typing_extensions-4.9.0:\n",
      "      Successfully uninstalled typing_extensions-4.9.0\n",
      "Successfully installed jiter-0.5.0 langchain-openai-0.1.21 openai-1.40.6 tiktoken-0.7.0 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-anthropic\n",
      "  Downloading langchain_anthropic-0.1.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting anthropic<1,>=0.28.0 (from langchain-anthropic)\n",
      "  Downloading anthropic-0.33.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.7.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.2.30)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (1.3.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.28.0->langchain-anthropic) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (0.1.99)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (23.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (8.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.28.0->langchain-anthropic) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.28.0->langchain-anthropic) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain-anthropic) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain-anthropic) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.28.0->langchain-anthropic) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<1,>=0.28.0->langchain-anthropic) (2.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain-anthropic) (0.24.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain-anthropic) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain-anthropic) (2024.2.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.28.0->langchain-anthropic) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain-anthropic) (2.2.0)\n",
      "Downloading langchain_anthropic-0.1.22-py3-none-any.whl (20 kB)\n",
      "Downloading anthropic-0.33.1-py3-none-any.whl (866 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m866.9/866.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: anthropic, langchain-anthropic\n",
      "Successfully installed anthropic-0.33.1 langchain-anthropic-0.1.22\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.24.5)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.2.30)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface)\n",
      "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.19.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.44.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.1.99)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.26.3)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain-huggingface) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.101)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sentence-transformers, langchain-huggingface\n",
      "Successfully installed joblib-1.4.2 langchain-huggingface-0.0.3 scikit-learn-1.5.1 scipy-1.14.0 sentence-transformers-3.0.1 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.24.9 (from PyMuPDF)\n",
      "  Downloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.9 PyMuPDFb-1.24.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.26.3)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.7)\n",
      "Collecting httpx>=0.27.0 (from chromadb)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.33.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.3)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.24.5)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading chromadb-0.5.5-py3-none-any.whl (584 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m584.3/584.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading google_auth-2.33.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.4-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m427.7/427.7 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53726 sha256=1e260bc1ebd5d17288a6a06922dfccf8ef2658cbbb8d373ab75fa328047ca8a3\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, flatbuffers, wrapt, websockets, uvloop, shellingham, python-dotenv, pyproject_hooks, pyasn1, protobuf, opentelemetry-util-http, oauthlib, mdurl, importlib-resources, importlib-metadata, humanfriendly, httptools, grpcio, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, httpx, googleapis-common-protos, deprecated, coloredlogs, build, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, fastapi, typer, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "  Attempting uninstall: oauthlib\n",
      "    Found existing installation: oauthlib 3.2.0\n",
      "    Uninstalling oauthlib-3.2.0:\n",
      "      Successfully uninstalled oauthlib-3.2.0\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.6.4\n",
      "    Uninstalling importlib-metadata-4.6.4:\n",
      "      Successfully uninstalled importlib-metadata-4.6.4\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.26.0\n",
      "    Uninstalling httpx-0.26.0:\n",
      "      Successfully uninstalled httpx-0.26.0\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.1 cachetools-5.4.0 chroma-hnswlib-0.7.6 chromadb-0.5.5 click-8.1.7 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.112.0 flatbuffers-24.3.25 google-auth-2.33.0 googleapis-common-protos-1.63.2 grpcio-1.65.4 httptools-0.6.1 httpx-0.27.0 humanfriendly-10.0 importlib-metadata-8.0.0 importlib-resources-6.4.0 kubernetes-30.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 oauthlib-3.2.2 onnxruntime-1.18.1 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 posthog-3.5.0 protobuf-4.25.4 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 shellingham-1.5.4 starlette-0.37.2 typer-0.12.3 uvicorn-0.30.6 uvloop-0.19.0 watchfiles-0.23.0 websockets-12.0 wrapt-1.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.5.1)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.5)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.51.2->umap-learn)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
      "Downloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.60.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llvmlite, numba, pynndescent, umap-learn\n",
      "Successfully installed llvmlite-0.43.0 numba-0.60.0 pynndescent-0.5.13 umap-learn-0.5.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ê°€ì†í™” ë° ë©”ëª¨ë¦¬ ê´€ë¦¬\n",
    "%pip install accelerate\n",
    "%pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "\n",
    "# Transformer ê¸°ë°˜ ëª¨ë¸ê³¼ ë°ì´í„°ì…‹ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "%pip install transformers[torch] -U\n",
    "%pip install datasets\n",
    "\n",
    "# LangChain ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "%pip install langchain\n",
    "%pip install langchainhub\n",
    "%pip install langchain_community\n",
    "%pip install langchain-openai\n",
    "%pip install langchain-anthropic\n",
    "%pip install langchain-huggingface\n",
    "\n",
    "# ë¬¸ì„œ ì²˜ë¦¬ ë° ë¬¸ì„œ ì„ë² ë”© ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "%pip install PyMuPDF\n",
    "%pip install sentence-transformers\n",
    "\n",
    "# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "%pip install faiss-cpu\n",
    "# %pip install faiss-gpu\n",
    "%pip install chromadb\n",
    "\n",
    "# ë°ì´í„° ì‹œê°í™” ë° ë¶„ì„ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "%pip install umap-learn\n",
    "%pip install scikit-learn\n",
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import unicodedata\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF\n",
    "import umap\n",
    "\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForCausalLM,\n",
    ")\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RAPTOR íŠ¸ë¦¬ êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. UMAP ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê¸€ë¡œë²Œ ì„ë² ë”© ì°¨ì› ì¶•ì†Œ í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "- ì „ì—­ í´ëŸ¬ìŠ¤í„°ë§ì€ ë°ì´í„° ë‚´ì˜ ì „ë°˜ì ì¸ ì „ì²´ íŒ¨í„´ì„ ì´í•´í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤. <br>\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `global_cluster_embeddings(embeddings, dim, n_neighbors, metric) -> np.ndarray`\n",
    "\n",
    "<br>\n",
    "\n",
    "> **UMAP (Univorm Manifold Approximation and Projection)**\n",
    "- ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ëŠ” ë¹„ì„ í˜• ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "- ì£¼ë¡œ ì‹œê°í™”ì™€ í´ëŸ¬ìŠ¤í„°ë§ ì§€ì›í•˜ëŠ”ë° ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- UMAPì€ ë°ì´í„° í¬ì¸íŠ¸ ê°„ì˜ ìœ ì‚¬ì„±ì„ ìœ ì§€í•˜ë©°, ë°ì´í„°ë¥¼ ë‚®ì€ ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•˜ì—¬ ì¤‘ìš”í•œ íŒ¨í„´ì„ ì‰½ê²Œ ë¶„ì„í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2024  # ì¬í˜„ì„±ì„ ìœ„í•œ ê³ ì •ëœ ì‹œë“œ ê°’\n",
    "\n",
    "def global_cluster_embeddings(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    n_neighbors: Optional[int] = None,\n",
    "    metric: str = \"cosine\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    UMAPì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì˜ ì „ì—­ ì°¨ì› ì¶•ì†Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - embeddings  : numpy ë°°ì—´ë¡œ ëœ ì…ë ¥ ì„ë² ë”©.\n",
    "    - dim         : ì¶•ì†Œí•  ì°¨ì› ê°’.\n",
    "    - n_neighbors : ì„ íƒ ì‚¬í•­; ê° ì ì„ ê³ ë ¤í•  ì´ì›ƒì˜ ìˆ˜. (ê¸°ë³¸ê°’ : ì„ë² ë”© ìˆ˜ì˜ ì œê³±ê·¼)\n",
    "    - metric      : UMAPì— ì‚¬ìš©í•  ê±°ë¦¬ ì¸¡ì • ê¸°ì¤€.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - ì§€ì •ëœ ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œëœ ì„ë² ë”©ì˜ numpy ë°°ì—´.\n",
    "    \"\"\"\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int((len(embeddings) - 1) ** 0.5)\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=n_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. UMAP ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ ì„ë² ë”© ì°¨ì› ì¶•ì†Œ í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "- ì§€ì—­ ì°¨ì› ì¶•ì†ŒëŠ” íŠ¹ì • ë°ì´í„° í¬ì¸íŠ¸ì™€ ê·¸ ì£¼ë³€ ë°ì´í„°ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ë” ì˜ ë°˜ì˜í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `local_cluster_embeddings(embeddings, dim, num_neighbors, metric) -> np.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_cluster_embeddings(\n",
    "    embeddings: np.ndarray, dim: int, num_neighbors: int = 10, metric: str = \"cosine\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ì„ë² ë”©ì— ëŒ€í•´ ì§€ì—­ ì°¨ì› ì¶•ì†Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì „ì—­ í´ëŸ¬ìŠ¤í„°ë§ ì´í›„ì— ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - embeddings    : numpy ë°°ì—´ë¡œì„œì˜ ì…ë ¥ ì„ë² ë”©.\n",
    "    - dim           : ì¶•ì†Œí•  ì°¨ì› ê°’.\n",
    "    - num_neighbors : ê° ì ì— ëŒ€í•´ ê³ ë ¤í•  ì´ì›ƒì˜ ìˆ˜.\n",
    "    - metric        : UMAPì— ì‚¬ìš©í•  ê±°ë¦¬ ì¸¡ì • ê¸°ì¤€.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - ì§€ì •ëœ ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œëœ ì„ë² ë”©ì˜ numpy ë°°ì—´.\n",
    "    \"\"\"\n",
    "    return umap.UMAP(\n",
    "        n_neighbors=num_neighbors, n_components=dim, metric=metric\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3. GMMê³¼ BICë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì • í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "- ì£¼ì–´ì§„ ì„ë² ë”© ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ê²°ì •í•˜ëŠ”ë° ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- ì¦‰, í´ëŸ¬ìŠ¤í„°ë§ ë¬¸ì œì—ì„œ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì°¾ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- **ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸(Gaussian Mixture Model, GMM)** ê³¼ **ë² ì´ì§€ì•ˆ ì •ë³´ ê¸°ì¤€(BIC)** ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `get_optimal_clusters(embeddings, max_clusters, random_state) -> int`\n",
    "\n",
    "<br>\n",
    "\n",
    "> **GMM (Gaussian Mixture Model, ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸)**\n",
    "- ë‹¤ì–‘í•œ í´ëŸ¬ìŠ¤í„°ì— ê±¸ì³ ë°ì´í„° í¬ì¸íŠ¸ì˜ ë¶„í¬ë¥¼ ëª¨ë¸ë§í•©ë‹ˆë‹¤.\n",
    "- ëª¨ë¸ì˜ ë² ì´ì§€ì•ˆ ì •ë³´ ê¸°ì¤€(BIC)ë¥¼ í‰ê°€í•˜ì—¬ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "> **BIC (Bayesian Information Criterion, ë² ì´ì§€ì•ˆ ì •ë³´ ê¸°ì¤€)**\n",
    "- ëª¨ë¸ì˜ ì í•©ë„ì™€ ë³µì¡ë„ ê°„ì˜ ê· í˜•ì„ ë§ì¶”ëŠ” ì§€í‘œë¡œ, ë„ˆë¬´ ë§ì€ í´ëŸ¬ìŠ¤í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³¼ì í•©ë˜ëŠ” ê²ƒì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
    "- ë”°ë¼ì„œ, ì´ í•¨ìˆ˜ëŠ” ë³µì¡ì„±ì„ ìµœì†Œí™”í•˜ë©´ì„œë„ ë°ì´í„°ë¥¼ ì˜ ì„¤ëª…í•˜ëŠ” í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ì°¾ëŠ”ë° ìœ ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_clusters(\n",
    "    embeddings: np.ndarray, max_clusters: int = 50, random_state: int = RANDOM_SEED\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸(Gaussian Mixture Model)ì„ ì‚¬ìš©í•˜ì—¬ ë² ì´ì§€ì•ˆ ì •ë³´ ê¸°ì¤€(BIC)ì„ í†µí•´ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - embeddings: numpy ë°°ì—´ë¡œì„œì˜ ì…ë ¥ ì„ë² ë”©.\n",
    "    - max_clusters: ê³ ë ¤í•  ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ìˆ˜.\n",
    "    - random_state: ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - ë°œê²¬ëœ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì •ìˆ˜.\n",
    "    \"\"\"\n",
    "    max_clusters = min(max_clusters, len(embeddings))  # ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ìˆ˜ì™€ ì„ë² ë”©ì˜ ê¸¸ì´ ì¤‘ ì‘ì€ ê°’ì„ ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¡œ ì„¤ì •\n",
    "    n_clusters = np.arange(1, max_clusters)            # 1ë¶€í„° ìµœëŒ€ í´ëŸ¬ìŠ¤í„° ìˆ˜ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ ìƒì„±\n",
    "    bics = []                                          # BIC ì ìˆ˜ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
    "    for n in n_clusters: # ê° í´ëŸ¬ìŠ¤í„° ìˆ˜ì— ëŒ€í•´ ë°˜ë³µ\n",
    "        gm = GaussianMixture(n_components=n, random_state=random_state) # ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "        gm.fit(embeddings)              # ì„ë² ë”©ì— ëŒ€í•´ ëª¨ë¸ í•™ìŠµ\n",
    "        bics.append(gm.bic(embeddings)) # í•™ìŠµëœ ëª¨ë¸ì˜ BIC ì ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "    return n_clusters[np.argmin(bics)]  # BIC ì ìˆ˜ê°€ ê°€ì¥ ë‚®ì€ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-4. ì£¼ì–´ì§„ ì„ë² ë”© ë°ì´í„°ì— ëŒ€í•´ GMMì„ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "- ê° ë°ì´í„° í¬ì¸íŠ¸(ì„ë² ë”©)ê°€ íŠ¹ì • í´ëŸ¬ìŠ¤í„°ì— ì†í•  í™•ë¥ ì„ ê³„ì‚°í•˜ê³ , í™•ë¥  ì„ê³„ê°’ì„ ì‚¬ìš©í•˜ì—¬ ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "- ì´ ê³¼ì •ì€ í™•ë¥  ì„ê³„ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜í–‰ë©ë‹ˆë‹¤.\n",
    "- ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ì´ì „ì— êµ¬í˜„í•´ë‘” `get_optimal_clusters`í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "- ê²°ì •ëœ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸ì„ ì´ˆê¸°í™”í•˜ê³ , ì…ë ¥ëœ ì„ë² ë”©ì— ëŒ€í•´ í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "- ê° ì„ë² ë”©ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° í• ë‹¹ í™•ë¥ ì„ ê³„ì‚°í•˜ê³ , ì´ í™•ë¥ ì´ ì£¼ì–´ì§„ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” ê²½ìš° í•´ë‹¹ ì„ë² ë”©ì„ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "- í•¨ìˆ˜ëŠ” ìµœì¢…ì ìœ¼ë¡œ ì„ë² ë”©ì˜ í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”ê³¼ ê²°ì •ëœ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ íŠœí”Œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `GMM_cluster(embeddings, threshold, random_state) -> labels, n_clusters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GMM_cluster(embeddings: np.ndarray, threshold: float, random_state: int = 0):\n",
    "    \"\"\"\n",
    "    í™•ë¥  ì„ê³„ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸(GMM)ì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©ì„ í´ëŸ¬ìŠ¤í„°ë§í•©ë‹ˆë‹¤.\n",
    "\n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - embeddings   : numpy ë°°ì—´ë¡œì„œì˜ ì…ë ¥ ì„ë² ë”©.\n",
    "    - threshold    : ì„ë² ë”©ì„ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹í•˜ê¸° ìœ„í•œ í™•ë¥  ì„ê³„ê°’.\n",
    "    - random_state : ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸”ê³¼ ê²°ì •ëœ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” íŠœí”Œ.\n",
    "    \"\"\"\n",
    "    n_clusters = get_optimal_clusters(embeddings)  # ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ êµ¬í•©ë‹ˆë‹¤.\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=random_state) # ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "    gm.fit(embeddings)                                         # ì„ë² ë”©ì— ëŒ€í•´ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "    probs = gm.predict_proba(embeddings)                       # ì„ë² ë”©ì´ ê° í´ëŸ¬ìŠ¤í„°ì— ì†í•  í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
    "    labels = [np.where(prob > threshold)[0] for prob in probs] # ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ” í™•ë¥ ì„ ê°€ì§„ í´ëŸ¬ìŠ¤í„°ë¥¼ ë ˆì´ë¸”ë¡œ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "    return labels, n_clusters                                  # ë ˆì´ë¸”ê³¼ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-5. ê³ ì°¨ì› ì„ë² ë”© ë°ì´í„°ë¥¼ ë‹¤ë‹¨ê³„ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "- ì°¨ì› ì¶•ì†Œ, ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ë§, ê° ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ë³´ë‹¤ ì„¸ë¶„í™”ëœ ë°©ì‹ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ í•©ë‹ˆë‹¤.\n",
    "- ì´ ê³¼ì •ì€ ê³ ì°¨ì› ë°ì´í„°ì˜ ë³µì¡í•œ êµ¬ì¡°ë¥¼ ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ë‹¤ì–‘í•œ ê·œëª¨ì—ì„œì˜ íŒ¨í„´ì„ í¬ì°©í•˜ëŠ”ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `perform_clustering(embeddings, dim, threshold) -> List[np.ndarray]`\n",
    "\n",
    "> ë™ì‘ ê³¼ì •\n",
    "1. ì„ë² ë”© í¬ê¸° í™•ì¸\n",
    "    - ì…ë ¥ëœ ì„ë² ë”©ì˜ ìˆ˜ê°€ `dim`+1 ë³´ë‹¤ ì‘ê±°ë‚˜ ê°™ë‹¤ë©´, ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨í•˜ê³  ê¸°ë³¸ì ìœ¼ë¡œ ê° ì„ë² ë”©ì„ í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„°ë¡œ í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "2. ê¸€ë¡œë²Œ ì°¨ì› ì¶•ì†Œ\n",
    "    - **UMAP** ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì„ë² ë”©ì˜ ì°¨ì›ì„ `dim`ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œí•©ë‹ˆë‹¤. ì´ ê³¼ì •ì„ í†µí•´ ê³ ì°¨ì› ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê¸° ë” ìš©ì´í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.\n",
    "    - `global_cluster_embeddings` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì°¨ì› ì¶•ì†Œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "3. ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ë§\n",
    "    - ì¶•ì†Œëœ ì„ë² ë”©ì— ëŒ€í•´ **GMM**ì„ ì‚¬ìš©í•˜ì—¬ ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    - `GMM_cluster` í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœì ì˜ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ì°¾ê³ , ê° ì„ë² ë”©ì´ ì†í•œ ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "4. ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ë§\n",
    "    - ê° ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ì„ë² ë”©ì— ëŒ€í•´ ì¶”ê°€ì ì¸ ë¡œì»¬ ì°¨ì› ì¶•ì†Œ ë° í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    - ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ì„ë² ë”©ë“¤ì„ ì¶”ì¶œí•œ í›„, ë‹¤ì‹œ **UMAP**ì„ ì‚¬ìš©í•˜ì—¬ ì°¨ì› ì¶•ì†Œë¥¼ í•˜ê³ , **GMM**ì„ ì‚¬ìš©í•˜ì—¬ `local_cluster_embeddings` í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•´ ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    - ê° ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ì— ì†í•œ ì„ë² ë”©ì— ëŒ€í•´ í´ëŸ¬ìŠ¤í„° IDë¥¼ í• ë‹¹í•©ë‹ˆë‹¤.\n",
    "5. í´ëŸ¬ìŠ¤í„° ID í• ë‹¹\n",
    "    - ê° ì„ë² ë”©ì— ëŒ€í•´ í• ë‹¹ëœ ê¸€ë¡œë²Œ ë° ë¡œì»¬ í´ëŸ¬ìŠ¤í„° IDë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ì„ë² ë”©ì´ ì†í•˜ëŠ” í´ëŸ¬ìŠ¤í„°ë¥¼ ì‹ë³„í•©ë‹ˆë‹¤.\n",
    "    - ì´ ê³¼ì •ì—ì„œ ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ê°€ ìµœì¢… í´ëŸ¬ìŠ¤í„° IDë¡œ í¬í•¨ë©ë‹ˆë‹¤.\n",
    "6. ê²°ê³¼ ë°˜í™˜\n",
    "    - ê° ì„ë² ë”©ì´ ì†í•˜ëŠ” ìµœì¢… í´ëŸ¬ìŠ¤í„° ID ë°°ì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ë°°ì—´ì€ ëª¨ë“  ì„ë² ë”©ì— ëŒ€í•´ ê¸€ë¡œë²Œ ë° ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ë¥¼ ê²°í•©í•œ IDë¥¼ í¬í•¨í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_clustering(\n",
    "    embeddings: np.ndarray,\n",
    "    dim: int,\n",
    "    threshold: float,\n",
    ") -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    ì„ë² ë”©ì— ëŒ€í•´ ì°¨ì› ì¶•ì†Œ, ê°€ìš°ì‹œì•ˆ í˜¼í•© ëª¨ë¸ì„ ì‚¬ìš©í•œ í´ëŸ¬ìŠ¤í„°ë§, ê° ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œì˜ ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆœì„œëŒ€ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - embeddings : numpy ë°°ì—´ë¡œ ëœ ì…ë ¥ ì„ë² ë”©.\n",
    "    - dim        : UMAP ì¶•ì†Œë¥¼ ìœ„í•œ ëª©í‘œ ì°¨ì›.\n",
    "    - threshold  : GMMì—ì„œ ì„ë² ë”©ì„ í´ëŸ¬ìŠ¤í„°ì— í• ë‹¹í•˜ê¸° ìœ„í•œ í™•ë¥  ì„ê³„ê°’.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - ê° ì„ë² ë”©ì˜ í´ëŸ¬ìŠ¤í„° IDë¥¼ í¬í•¨í•˜ëŠ” numpy ë°°ì—´ì˜ ë¦¬ìŠ¤íŠ¸.\n",
    "    \"\"\"\n",
    "    if len(embeddings) <= dim + 1:\n",
    "        # ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•Šì„ ë•Œ í´ëŸ¬ìŠ¤í„°ë§ì„ í”¼í•©ë‹ˆë‹¤.\n",
    "        return [np.array([0]) for _ in range(len(embeddings))]\n",
    "\n",
    "    # ê¸€ë¡œë²Œ ì°¨ì› ì¶•ì†Œ\n",
    "    reduced_embeddings_global = global_cluster_embeddings(embeddings, dim)\n",
    "    # ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ë§\n",
    "    global_clusters, n_global_clusters = GMM_cluster(\n",
    "        reduced_embeddings_global, threshold\n",
    "    )\n",
    "\n",
    "    all_local_clusters = [np.array([]) for _ in range(len(embeddings))]\n",
    "    total_clusters = 0\n",
    "\n",
    "    # ê° ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ë¥¼ ìˆœíšŒí•˜ë©° ë¡œì»¬ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰\n",
    "    for i in range(n_global_clusters):\n",
    "        # í˜„ì¬ ê¸€ë¡œë²Œ í´ëŸ¬ìŠ¤í„°ì— ì†í•˜ëŠ” ì„ë² ë”© ì¶”ì¶œ\n",
    "        global_cluster_embeddings_ = embeddings[\n",
    "            np.array([i in gc for gc in global_clusters])\n",
    "        ]\n",
    "\n",
    "        if len(global_cluster_embeddings_) == 0:\n",
    "            continue\n",
    "        if len(global_cluster_embeddings_) <= dim + 1:\n",
    "            # ì‘ì€ í´ëŸ¬ìŠ¤í„°ëŠ” ì§ì ‘ í• ë‹¹ìœ¼ë¡œ ì²˜ë¦¬\n",
    "            local_clusters = [np.array([0]) for _ in global_cluster_embeddings_]\n",
    "            n_local_clusters = 1\n",
    "        else:\n",
    "            # ë¡œì»¬ ì°¨ì› ì¶•ì†Œ ë° í´ëŸ¬ìŠ¤í„°ë§\n",
    "            reduced_embeddings_local = local_cluster_embeddings(\n",
    "                global_cluster_embeddings_, dim\n",
    "            )\n",
    "            local_clusters, n_local_clusters = GMM_cluster(\n",
    "                reduced_embeddings_local, threshold\n",
    "            )\n",
    "\n",
    "        # ë¡œì»¬ í´ëŸ¬ìŠ¤í„° ID í• ë‹¹, ì´ë¯¸ ì²˜ë¦¬ëœ ì´ í´ëŸ¬ìŠ¤í„° ìˆ˜ë¥¼ ì¡°ì •\n",
    "        for j in range(n_local_clusters):\n",
    "            local_cluster_embeddings_ = global_cluster_embeddings_[\n",
    "                np.array([j in lc for lc in local_clusters])\n",
    "            ]\n",
    "            indices = np.where(\n",
    "                (embeddings == local_cluster_embeddings_[:, None]).all(-1)\n",
    "            )[1]\n",
    "            for idx in indices:\n",
    "                all_local_clusters[idx] = np.append(\n",
    "                    all_local_clusters[idx], j + total_clusters\n",
    "                )\n",
    "\n",
    "        total_clusters += n_local_clusters\n",
    "\n",
    "    return all_local_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-6. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë¬¸ì„œì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "- embd ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•œ í›„, í´ëŸ¬ìŠ¤í„°ë§í•˜ê³  ì›ë³¸ í…ìŠ¤íŠ¸, í•´ë‹¹ ì„ë² ë”©, ê·¸ë¦¬ê³  í• ë‹¹ëœ í´ëŸ¬ìŠ¤í„° ë¼ë²¨ì„ í¬í•¨í•˜ëŠ” `pandas.DataFrame`ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `embed(texts) -> numpy.ndarray`\n",
    "\n",
    "> ë™ì‘ ê³¼ì •\n",
    "- ì…ë ¥ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¬¸ì„œì˜ ëª©ë¡(`texts`)ì„ ë°›ìŠµë‹ˆë‹¤.\n",
    "- `embd` ê°ì²´ì˜ `embed_documents` ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¬¸ì„œì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- ìƒì„±ëœ ì„ë² ë”©ì„ `numpy.ndarray` í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(texts, embeddings):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ ë¬¸ì„œ ëª©ë¡ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    embeddings ê°ì²´ëŠ” í…ìŠ¤íŠ¸ ëª©ë¡ì„ ë°›ì•„ ê·¸ ì„ë² ë”©ì„ ë°˜í™˜í•˜ëŠ” `embed_documents` ë©”ì†Œë“œë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "    \n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - texts: List[str], ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¬¸ì„œì˜ ëª©ë¡ì…ë‹ˆë‹¤.\n",
    "    \n",
    "    ë°˜í™˜ê°’:\n",
    "    - numpy.ndarray: ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì— ëŒ€í•œ ì„ë² ë”© ë°°ì—´ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # text_embeddings = embeddings.embed_documents(\n",
    "    #     texts\n",
    "    # )  # í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    # text_embeddings_np = np.array(text_embeddings) \n",
    "\n",
    "    # 'texts'ê°€ ë¬¸ìì—´ ëª©ë¡ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    if isinstance(texts[0], str):\n",
    "        text_contents = texts\n",
    "    else:\n",
    "        # ë§Œì•½ 'texts'ê°€ 'Document' ê°ì²´ë¡œ ì´ë£¨ì–´ì§„ ë¦¬ìŠ¤íŠ¸ë¼ë©´, 'page_content'ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "        text_contents = [doc.page_content for doc in texts]\n",
    "    \n",
    "    text_embeddings = embeddings.embed_documents(text_contents)  # í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    text_embeddings_np = np.array(text_embeddings)  # ì„ë² ë”©ì„ numpy ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    return text_embeddings_np                      # ì„ë² ë”©ëœ numpy ë°°ì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-7. í…ìŠ¤íŠ¸ ë°ì´í„°ì˜ êµ¬ì¡°ì  ë¶„ì„, ê·¸ë£¹í™”ë¥¼ ìœ„í•œ í†µí•© íŒŒì´í”„ë¼ì¸ êµ¬í˜„\n",
    "\n",
    "- ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ëª©ë¡ì— ëŒ€í•´ ì„ë² ë”©ì„ ìƒì„±í•˜ê³ , ìƒì„±ëœ ì„ë² ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ì›ë³¸ í…ìŠ¤íŠ¸, í•´ë‹¹ ì„ë² ë”©, ê·¸ë¦¬ê³  í• ë‹¹ëœ í´ëŸ¬ìŠ¤í„° ë¼ë²¨ì„ í¬í•¨í•˜ëŠ” **pandas.DataFrame**ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `embed_cluster_texts(texts) -> df`\n",
    "\n",
    "> ë™ì‘ ê³¼ì •\n",
    "1. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ëª©ë¡ì— ëŒ€í•´ ì„ë² ë”© ìƒì„± (ì„ë² ë”© ìƒì„±ì„ ìœ„í•´ `embed()`ì‚¬ìš©)\n",
    "2. ìƒì„±ëœ ì„ë² ë”©ì„ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰, ì´ ê³¼ì •ì€ ì‚¬ì „ì— ì •ì˜ëœ `perform_clustering()`í•¨ìˆ˜ë¥¼ ì‚¬ìš©\n",
    "3. ê²°ê³¼ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ **pandas.DataFrame**ì„ ì´ˆê¸°í™”\n",
    "4. DataFrameì— ì›ë³¸ í…ìŠ¤íŠ¸, ì„ë² ë”© ë¦¬ìŠ¤íŠ¸, í´ëŸ¬ìŠ¤í„° ë¼ë²¨ì„ ê°ê° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_texts(texts, embeddings):\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ ëª©ë¡ì„ ì„ë² ë”©í•˜ê³  í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬, í…ìŠ¤íŠ¸, ê·¸ë“¤ì˜ ì„ë² ë”©, ê·¸ë¦¬ê³  í´ëŸ¬ìŠ¤í„° ë¼ë²¨ì´ í¬í•¨ëœ DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    ì´ í•¨ìˆ˜ëŠ” ì„ë² ë”© ìƒì„±ê³¼ í´ëŸ¬ìŠ¤í„°ë§ì„ ë‹¨ì¼ ë‹¨ê³„ë¡œ ê²°í•©í•©ë‹ˆë‹¤. ì„ë² ë”©ì— ëŒ€í•´ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•˜ëŠ” `perform_clustering` í•¨ìˆ˜ì˜ ì‚¬ì „ ì •ì˜ëœ ì¡´ì¬ë¥¼ ê°€ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - texts: List[str], ì²˜ë¦¬ë  í…ìŠ¤íŠ¸ ë¬¸ì„œì˜ ëª©ë¡ì…ë‹ˆë‹¤.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - pandas.DataFrame: ì›ë³¸ í…ìŠ¤íŠ¸, ê·¸ë“¤ì˜ ì„ë² ë”©, ê·¸ë¦¬ê³  í• ë‹¹ëœ í´ëŸ¬ìŠ¤í„° ë¼ë²¨ì´ í¬í•¨ëœ DataFrameì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    text_embeddings_np = embed(texts, embeddings) # ì„ë² ë”© ìƒì„±\n",
    "    cluster_labels = perform_clustering(\n",
    "        text_embeddings_np, 10, 0.1\n",
    "    )  # ì„ë² ë”©ì— ëŒ€í•´ í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰\n",
    "    df = pd.DataFrame()                   # ê²°ê³¼ë¥¼ ì €ì¥í•  DataFrame ì´ˆê¸°í™”\n",
    "    df[\"text\"] = texts                    # ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥\n",
    "    df[\"embd\"] = list(text_embeddings_np) # DataFrameì— ë¦¬ìŠ¤íŠ¸ë¡œ ì„ë² ë”© ì €ì¥\n",
    "    df[\"cluster\"] = cluster_labels        # í´ëŸ¬ìŠ¤í„° ë¼ë²¨ ì €ì¥\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-8. í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ë‹¨ì¼ ë¬¸ìì—´ì„ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜ êµ¬í˜„\n",
    "\n",
    "- **pandas**ì˜ **DataFrame**ì—ì„œ `text` ì»¬ëŸ¼ì— ìˆëŠ” ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ë‹¨ì¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.\n",
    "- ê° í…ìŠ¤íŠ¸ ë¬¸ì„œëŠ” íŠ¹ì • êµ¬ë¶„ì(\"--- --- \\n --- --- \")ë¡œ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©°, ìµœì¢…ì ìœ¼ë¡œ ì—°ê²°ëœ í•˜ë‚˜ì˜ í° ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "- ì´ í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ í•˜ë‚˜ì˜ ê¸´ ë¬¸ìì—´ë¡œ ê²°í•©í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `fmt_txt(df) -> str`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_txt(df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    DataFrameì— ìˆëŠ” í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ë‹¨ì¼ ë¬¸ìì—´ë¡œ í¬ë§·í•©ë‹ˆë‹¤.\n",
    "\n",
    "    íŒŒë¼ë¯¸í„°:\n",
    "    - df: 'text' ì—´ì— í¬ë§·í•  í…ìŠ¤íŠ¸ ë¬¸ì„œê°€ í¬í•¨ëœ DataFrame.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - ëª¨ë“  í…ìŠ¤íŠ¸ ë¬¸ì„œê°€ íŠ¹ì • êµ¬ë¶„ìë¡œ ê²°í•©ëœ ë‹¨ì¼ ë¬¸ìì—´.\n",
    "    \"\"\"\n",
    "    # unique_txt = df[\"text\"].tolist()  # 'text' ì—´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    \n",
    "    # 'text' ì—´ì´ Document ê°ì²´ì¼ ê²½ìš°, page_contentë¥¼ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    unique_txt = [doc.page_content if isinstance(doc, Document) else doc for doc in df[\"text\"].tolist()]\n",
    "    return \"--- --- \\n --- --- \".join(unique_txt)  # í…ìŠ¤íŠ¸ ë¬¸ì„œë“¤ì„ íŠ¹ì • êµ¬ë¶„ìë¡œ ê²°í•©í•˜ì—¬ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-9. ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ëª©ë¡ì— ëŒ€í•´ ì„ë² ë”© ìƒì„±, í´ëŸ¬ìŠ¤í„°ë§, ê·¸ë¦¬ê³  í´ëŸ¬ìŠ¤í„° ë‚´ í…ìŠ¤íŠ¸ ìš”ì•½ì„ ë‹¨ê³„ì ìœ¼ë¡œ ìˆ˜í–‰í•˜ëŠ” íŒŒì´í”„ë¼ì¸ êµ¬ì¶•\n",
    "\n",
    "- í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ê³ , í´ëŸ¬ìŠ¤í„°ë§í•˜ë©°, ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "- ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ëª©ë¡ì— ëŒ€í•´ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ìœ ì‚¬ì„±ì— ê¸°ë°˜í•œ í´ëŸ¬ìŠ¤í„°ë§ì„ ì§„í–‰í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì€ `df_clusters` ë°ì´í„°í”„ë ˆì„ì„ ê²°ê³¼ë¡œ í•©ë‹ˆë‹¤. ì´ ë°ì´í„°í”„ë ˆì„ì—ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸, ì„ë² ë”©, ê·¸ë¦¬ê³  í´ëŸ¬ìŠ¤í„° í• ë‹¹ ì •ë³´ê°€ í¬í•¨ë©ë‹ˆë‹¤.\n",
    "- í´ëŸ¬ìŠ¤í„° í• ë‹¹ì„ ì‰½ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ë°ì´í„°í”„ë ˆì„ í•­ëª©ì„ í™•ì¥í•©ë‹ˆë‹¤. ê° í–‰ì€ í…ìŠ¤íŠ¸, ì„ë² ë”©, í´ëŸ¬ìŠ¤í„°ë¥¼ í¬í•¨í•˜ëŠ” ìƒˆë¡œìš´ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.\n",
    "- í™•ì¥ëœ ë°ì´í„°í”„ë ˆì„ì—ì„œ ê³ ìœ í•œ í´ëŸ¬ìŠ¤í„° ì‹ë³„ìë¥¼ ì¶”ì¶œí•˜ê³ , ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤. ì´ ìš”ì•½ì€ `df_summary` ë°ì´í„°í”„ë ˆì„ì— ì €ì¥ë©ë‹ˆë‹¤. ì´ ë°ì´í„°í”„ë ˆì„ì€ ê° í´ëŸ¬ìŠ¤í„°ì˜ ìš”ì•½, ì§€ì •ëœ ì„¸ë¶€ ìˆ˜ì¤€, ê·¸ë¦¬ê³  í´ëŸ¬ìŠ¤í„° ì‹ë³„ìë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "- ìµœì¢…ì ìœ¼ë¡œ, í•¨ìˆ˜ëŠ” ë‘ ê°œì˜ ë°ì´í„°í”„ë ˆì„ì„ í¬í•¨í•˜ëŠ” íŠœí”Œì„ ë°˜í™˜í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ì€ ì›ë³¸ í…ìŠ¤íŠ¸, ì„ë² ë”©, í´ëŸ¬ìŠ¤í„° í• ë‹¹ ì •ë³´ë¥¼ í¬í•¨í•˜ë©°, ë‘ ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„ì€ ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ ìš”ì•½ê³¼ í•´ë‹¹ ì„¸ë¶€ ìˆ˜ì¤€, í´ëŸ¬ìŠ¤í„° ì‹ë³„ìë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "- êµ¬í˜„ í•¨ìˆ˜ : `embd_cluster_summarize_texts(texts: List[str], level: int) -> Tuple[pd.DataFrame, pd.DataFrame]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_cluster_summarize_texts(\n",
    "    texts: List[str], level: int, embeddings, model\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ ëª©ë¡ì— ëŒ€í•´ ì„ë² ë”©, í´ëŸ¬ìŠ¤í„°ë§ ë° ìš”ì•½ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì´ í•¨ìˆ˜ëŠ” ë¨¼ì € í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•˜ê³ ,\n",
    "    ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•œ ë‹¤ìŒ, í´ëŸ¬ìŠ¤í„° í• ë‹¹ì„ í™•ì¥í•˜ì—¬ ì²˜ë¦¬ë¥¼ ìš©ì´í•˜ê²Œ í•˜ê³  ê° í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤.\n",
    "\n",
    "    ë§¤ê°œë³€ìˆ˜:\n",
    "    - texts: ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ ë¬¸ì„œ ëª©ë¡ì…ë‹ˆë‹¤.\n",
    "    - level: ì²˜ë¦¬ì˜ ê¹Šì´ë‚˜ ì„¸ë¶€ ì‚¬í•­ì„ ì •ì˜í•  ìˆ˜ ìˆëŠ” ì •ìˆ˜ ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - ë‘ ê°œì˜ ë°ì´í„°í”„ë ˆì„ì„ í¬í•¨í•˜ëŠ” íŠœí”Œ:\n",
    "      1. ì²« ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„(`df_clusters`)ì€ ì›ë³¸ í…ìŠ¤íŠ¸, ê·¸ë“¤ì˜ ì„ë² ë”©, ê·¸ë¦¬ê³  í´ëŸ¬ìŠ¤í„° í• ë‹¹ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "      2. ë‘ ë²ˆì§¸ ë°ì´í„°í”„ë ˆì„(`df_summary`)ì€ ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ ìš”ì•½, ì§€ì •ëœ ì„¸ë¶€ ìˆ˜ì¤€, ê·¸ë¦¬ê³  í´ëŸ¬ìŠ¤í„° ì‹ë³„ìë¥¼ í¬í•¨í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•˜ê³  í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ 'text', 'embd', 'cluster' ì—´ì´ ìˆëŠ” ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    df_clusters = embed_cluster_texts(texts, embeddings)\n",
    "\n",
    "    # í´ëŸ¬ìŠ¤í„°ë¥¼ ì‰½ê²Œ ì¡°ì‘í•˜ê¸° ìœ„í•´ ë°ì´í„°í”„ë ˆì„ì„ í™•ì¥í•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.\n",
    "    expanded_list = []\n",
    "\n",
    "    # ë°ì´í„°í”„ë ˆì„ í•­ëª©ì„ ë¬¸ì„œ-í´ëŸ¬ìŠ¤í„° ìŒìœ¼ë¡œ í™•ì¥í•˜ì—¬ ì²˜ë¦¬ë¥¼ ê°„ë‹¨í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        for cluster in row[\"cluster\"]:\n",
    "            expanded_list.append(\n",
    "                {\"text\": row[\"text\"], \"embd\": row[\"embd\"], \"cluster\": cluster}\n",
    "            )\n",
    "\n",
    "    # í™•ì¥ëœ ëª©ë¡ì—ì„œ ìƒˆ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    expanded_df = pd.DataFrame(expanded_list)\n",
    "\n",
    "    # ì²˜ë¦¬ë¥¼ ìœ„í•´ ê³ ìœ í•œ í´ëŸ¬ìŠ¤í„° ì‹ë³„ìë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "    all_clusters = expanded_df[\"cluster\"].unique()\n",
    "\n",
    "    print(f\"--Generated {len(all_clusters)} clusters--\")\n",
    "\n",
    "    # ìš”ì•½\n",
    "    template = \"\"\"ì—¬ê¸° LangChain í‘œí˜„ ì–¸ì–´ ë¬¸ì„œì˜ í•˜ìœ„ ì§‘í•©ì´ ìˆìŠµë‹ˆë‹¤.\n",
    "    \n",
    "    LangChain í‘œí˜„ ì–¸ì–´ëŠ” LangChainì—ì„œ ì²´ì¸ì„ êµ¬ì„±í•˜ëŠ” ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    ì œê³µëœ ë¬¸ì„œì˜ ìì„¸í•œ ìš”ì•½ì„ ì œê³µí•˜ì‹­ì‹œì˜¤.\n",
    "    \n",
    "    ë¬¸ì„œ:\n",
    "    {context}\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # ê° í´ëŸ¬ìŠ¤í„° ë‚´ì˜ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½ì„ ìœ„í•´ í¬ë§·íŒ…í•©ë‹ˆë‹¤.\n",
    "    summaries = []\n",
    "    for i in all_clusters:\n",
    "        df_cluster = expanded_df[expanded_df[\"cluster\"] == i]\n",
    "        formatted_txt = fmt_txt(df_cluster)\n",
    "        summaries.append(chain.invoke({\"context\": formatted_txt}))\n",
    "\n",
    "    # ìš”ì•½, í•´ë‹¹ í´ëŸ¬ìŠ¤í„° ë° ë ˆë²¨ì„ ì €ì¥í•  ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"summaries\": summaries,\n",
    "            \"level\": [level] * len(summaries),\n",
    "            \"cluster\": list(all_clusters),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_clusters, df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-10 í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì„ë² ë”©, í´ëŸ¬ìŠ¤í„°ë§ ë° ìš”ì•½í•˜ëŠ” ê³¼ì •ì„ êµ¬í˜„í•œ í•¨ìˆ˜\n",
    "\n",
    "- ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©, í´ëŸ¬ìŠ¤í„°ë§ ë° ìš”ì•½í•˜ì—¬ ê° ë‹¨ê³„ë³„ë¡œ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "- í•¨ìˆ˜ëŠ” ìµœëŒ€ ì§€ì •ëœ ì¬ê·€ ë ˆë²¨ê¹Œì§€ ì‹¤í–‰ë˜ê±°ë‚˜, ìœ ì¼í•œ í´ëŸ¬ìŠ¤í„°ì˜ ìˆ˜ê°€ 1ì´ ë  ë•Œê¹Œì§€ ë°˜ë³µë©ë‹ˆë‹¤.\n",
    "- ê° ì¬ê·€ ë‹¨ê³„ì—ì„œëŠ” í˜„ì¬ ë ˆë²¨ì˜ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ì™€ ìš”ì•½ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ ë°˜í™˜í•˜ê³ , ì´ë¥¼ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "- ë§Œì•½ í˜„ì¬ ë ˆë²¨ì´ ìµœëŒ€ ì¬ê·€ ë ˆë²¨ë³´ë‹¤ ì‘ê³ , ìœ ì¼í•œ í´ëŸ¬ìŠ¤í„°ì˜ ìˆ˜ê°€ 1ë³´ë‹¤ í¬ë‹¤ë©´, í˜„ì¬ ë ˆë²¨ì˜ ìš”ì•½ ê²°ê³¼ë¥¼ ë‹¤ìŒ ë ˆë²¨ì˜ ì…ë ¥ í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©í•˜ì—¬ ì¬ê·€ì ìœ¼ë¡œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "- ìµœì¢…ì ìœ¼ë¡œ ê° ë ˆë²¨ë³„ í´ëŸ¬ìŠ¤í„° ë°ì´í„°í”„ë ˆì„ê³¼ ìš”ì•½ ë°ì´í„°í”„ë ˆì„ì„ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_embed_cluster_summarize(\n",
    "    texts: List[str], embeddings, model, level: int = 1, n_levels: int = 3\n",
    ") -> Dict[int, Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    ì§€ì •ëœ ë ˆë²¨ê¹Œì§€ ë˜ëŠ” ê³ ìœ  í´ëŸ¬ìŠ¤í„°ì˜ ìˆ˜ê°€ 1ì´ ë  ë•Œê¹Œì§€ í…ìŠ¤íŠ¸ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì„ë² ë”©, í´ëŸ¬ìŠ¤í„°ë§, ìš”ì•½í•˜ì—¬\n",
    "    ê° ë ˆë²¨ì—ì„œì˜ ê²°ê³¼ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "    ë§¤ê°œë³€ìˆ˜:\n",
    "    - texts: List[str], ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ë“¤.\n",
    "    - level: int, í˜„ì¬ ì¬ê·€ ë ˆë²¨ (1ì—ì„œ ì‹œì‘).\n",
    "    - n_levels: int, ì¬ê·€ì˜ ìµœëŒ€ ê¹Šì´.\n",
    "\n",
    "    ë°˜í™˜ê°’:\n",
    "    - Dict[int, Tuple[pd.DataFrame, pd.DataFrame]], ì¬ê·€ ë ˆë²¨ì„ í‚¤ë¡œ í•˜ê³  í•´ë‹¹ ë ˆë²¨ì—ì„œì˜ í´ëŸ¬ìŠ¤í„° DataFrameê³¼ ìš”ì•½ DataFrameì„ í¬í•¨í•˜ëŠ” íŠœí”Œì„ ê°’ìœ¼ë¡œ í•˜ëŠ” ì‚¬ì „.\n",
    "    \"\"\"\n",
    "    results = {}  # ê° ë ˆë²¨ì—ì„œì˜ ê²°ê³¼ë¥¼ ì €ì¥í•  ì‚¬ì „\n",
    "\n",
    "    # í˜„ì¬ ë ˆë²¨ì— ëŒ€í•´ ì„ë² ë”©, í´ëŸ¬ìŠ¤í„°ë§, ìš”ì•½ ìˆ˜í–‰\n",
    "    df_clusters, df_summary = embed_cluster_summarize_texts(texts, level, embeddings, model)\n",
    "\n",
    "    # í˜„ì¬ ë ˆë²¨ì˜ ê²°ê³¼ ì €ì¥\n",
    "    results[level] = (df_clusters, df_summary)\n",
    "\n",
    "    # ì¶”ê°€ ì¬ê·€ê°€ ê°€ëŠ¥í•˜ê³  ì˜ë¯¸ê°€ ìˆëŠ”ì§€ ê²°ì •\n",
    "    unique_clusters = df_summary[\"cluster\"].nunique()\n",
    "    if level < n_levels and unique_clusters > 1:\n",
    "        # ë‹¤ìŒ ë ˆë²¨ì˜ ì¬ê·€ ì…ë ¥ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½ ì‚¬ìš©\n",
    "        new_texts = df_summary[\"summaries\"].tolist()\n",
    "        next_level_results = recursive_embed_cluster_summarize(\n",
    "            new_texts, embeddings, model, level + 1, n_levels\n",
    "        )\n",
    "\n",
    "        # ë‹¤ìŒ ë ˆë²¨ì˜ ê²°ê³¼ë¥¼ í˜„ì¬ ê²°ê³¼ ì‚¬ì „ì— ë³‘í•©\n",
    "        results.update(next_level_results)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. ëª¨ë¸ ì´ˆê¸°í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì„ë² ë”© ëª¨ë¸ì€ `intfloat/multilingual-e5-base`ì„ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤. <br>\n",
    "**Cached Embedding** ì„ ì‚¬ìš©í•˜ì—¬ í•œë²ˆ ê³„ì‚°ëœ ì„ë² ë”©ì„ ì €ì¥í•´ ë‘ì—ˆë‹¤ê°€, ë™ì¼í•œ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ì´ì „ì— ê³„ì‚°ëœ ì„ë² ë”© ê°’ì„ ê³„ì† í™œìš©í•˜ì—¬ ì¤‘ë³µ ê³„ì‚°ì„ í”¼í•©ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë¦¬ì†ŒìŠ¤ì„ ì¢€ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆì–´ ì—°ì‚° ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_embeddings(model_path=\"intfloat/multilingual-e5-base\"):\n",
    "    \"\"\"ì„ë² ë”© ëª¨ë¸ ì„¤ì • ë° ìºì‹œ ì‚¬ìš©\"\"\"\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embd = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    \n",
    "    store = LocalFileStore(\"./cache/\")\n",
    "    \n",
    "    # Cache Embedding ì‚¬ìš©\n",
    "    cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "        underlying_embeddings=embd, \n",
    "        document_embedding_cache=store, \n",
    "        namespace=model_path\n",
    "    )\n",
    "    \n",
    "    return cached_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ì „ì— `sh2orc/Llama-3.1-Korean-8B-Instruct`(Llama3 ëª¨ë¸ í•œêµ­ì–´ íŒŒì¸íŠœë‹ ëª¨ë¸)ì„ ëŒ€ìƒìœ¼ë¡œ GPTQ ì–‘ìí™” ì‹œì¼œì¤€ ëª¨ë¸ì„ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_llm_pipeline():\n",
    "    # ëª¨ë¸ ID (Hugging Face Hubì—ì„œ ê°€ì ¸ì˜¨ ì–‘ìí™”ëœ ëª¨ë¸ ID)\n",
    "    # model_id = \"ormor/Llama-3.1-Korean-8B-Instruct-GPTQ-4bit\"\n",
    "    # model_id = \"sh2orc/Llama-3.1-Korean-8B-Instruct\"\n",
    "    model_id = \"rtzr/ko-gemma-2-9b-it\"\n",
    "    \n",
    "    # í† í¬ë‚˜ì´ì € ë¡œë“œ ë° ì„¤ì •\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    tokenizer.use_default_system_prompt = False\n",
    "\n",
    "    # ëª¨ë¸ ë¡œë“œ ë° ì–‘ìí™” ì„¤ì • ì ìš©\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    print(f\"#### [ model ] ####\\n{model}\\n###################\")\n",
    "\n",
    "    # # DataParallelì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì—¬ëŸ¬ GPUì— í• ë‹¹\n",
    "    # if torch.cuda.device_count() > 1:\n",
    "    #     model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    # # ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
    "    # model = model.cuda()\n",
    "    \n",
    "    # HuggingFacePipeline ê°ì²´ ìƒì„±\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        return_full_text=False,\n",
    "        max_new_tokens=450,\n",
    "    )\n",
    "\n",
    "    hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "    return hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ë°ì´í„°ì…‹ ë¡œë“œ ë° ë²¡í„° DB ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(file_path, chunk_size=512, chunk_overlap=32):\n",
    "    \"\"\"PDF íŒŒì¼ë¡œë“œ, í…ìŠ¤íŠ¸ ì¶”ì¶œ\"\"\"\n",
    "    # PDF íŒŒì¼ ì—´ê¸°\n",
    "    doc = fitz.open(file_path)\n",
    "    doc_texts = []\n",
    "    \n",
    "    # ëª¨ë“  í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        text = page.get_text(\"text\")\n",
    "        doc_texts.append(Document(page_content=text, metadata={\"page\": page_num}))\n",
    "\n",
    "    return doc_texts    \n",
    "\n",
    "\n",
    "def normalize_path(path):\n",
    "    \"\"\"ê²½ë¡œ ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\"\"\"\n",
    "    return unicodedata.normalize('NFD', path)\n",
    "\n",
    "\n",
    "def process_pdfs_from_dataframe(df, base_directory, embeddings, model):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°í”„ë ˆì„ì—ì„œ PDF ì²˜ë¦¬, \n",
    "    ì—¬ëŸ¬ PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³ , ê° íŒŒì¼ì— ëŒ€í•´ ë²¡í„° DBì™€ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "    ë”•ì…”ë„ˆë¦¬ì— pdfëª…ì„ í‚¤ë¡œí•´ì„œ DB, retriever ì €ì¥\n",
    "    \"\"\"\n",
    "    pdf_databases = {}\n",
    "    unique_paths = df['Source_path'].unique()\n",
    "    \n",
    "    for path in tqdm(unique_paths, desc=\"Processing PDFs\"):\n",
    "        # ê²½ë¡œ ì •ê·œí™” ë° ì ˆëŒ€ ê²½ë¡œ ìƒì„±\n",
    "        normalized_path = normalize_path(path)\n",
    "        full_path = os.path.normpath(os.path.join(base_directory, normalized_path.lstrip('./'))) if not os.path.isabs(normalized_path) else normalized_path\n",
    "        \n",
    "        pdf_title = os.path.splitext(os.path.basename(full_path))[0]\n",
    "        print(f\"Processing {pdf_title}...\")\n",
    "        \n",
    "        # PDF ì²˜ë¦¬ \n",
    "        docs_texts = process_pdf(full_path)\n",
    "        \n",
    "        # íŠ¸ë¦¬ êµ¬ì¶•\n",
    "        # leaf_texts = docs_texts  # ë¬¸ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¦¬í”„ í…ìŠ¤íŠ¸ë¡œ ì„¤ì •\n",
    "        leaf_texts = [doc.page_content for doc in docs_texts]  # ë¬¸ì„œ í…ìŠ¤íŠ¸ë¥¼ ë¦¬í”„ í…ìŠ¤íŠ¸ë¡œ ì„¤ì •\n",
    "        results = recursive_embed_cluster_summarize(\n",
    "            leaf_texts, embeddings, model, level=1, n_levels=3\n",
    "        )  # ì¬ê·€ì ìœ¼ë¡œ ì„ë² ë”©, í´ëŸ¬ìŠ¤í„°ë§ ë° ìš”ì•½ì„ ìˆ˜í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ì–»ìŒ\n",
    "        \n",
    "        # leaf_textsë¥¼ ë³µì‚¬í•˜ì—¬ all_textsë¥¼ ì´ˆê¸°í™”\n",
    "        all_texts = leaf_texts.copy()\n",
    "        \n",
    "        # ê° ë ˆë²¨ì˜ ìš”ì•½ì„ ì¶”ì¶œí•˜ì—¬ all_textsì— ì¶”ê°€\n",
    "        for level in sorted(results.keys()):\n",
    "            summaries = results[level][1][\"summaries\"].tolist()  # í˜„ì¬ ë ˆë²¨ì˜ DataFrameì—ì„œ ìš”ì•½ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "            all_texts.extend(summaries) # í˜„ì¬ ë ˆë²¨ì˜ ìš”ì•½ì„ all_textsì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "        \n",
    "        # FAISS ë²¡í„° DB ìƒì„±\n",
    "        embeddings = setup_embeddings()\n",
    "        vectorstore = FAISS.from_texts(texts=all_texts, embedding=embeddings)\n",
    "        \n",
    "        # ë¡œì»¬ì— FAISS DB ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ìˆë‹¤ë©´ ë³‘í•©\n",
    "        DB_INDEX = f\"RAPTOR_{pdf_title}\"\n",
    "        if os.path.exists(DB_INDEX):\n",
    "            local_index = FAISS.load_local(DB_INDEX, embeddings)\n",
    "            local_index.merge_from(vectorstore)\n",
    "            local_index.save_local(DB_INDEX)\n",
    "        else:\n",
    "            vectorstore.save_local(folder_path=DB_INDEX)\n",
    "        \n",
    "        # Retriever ìƒì„±\n",
    "        retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={'k': 3, 'fetch_k': 8})\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        pdf_databases[pdf_title] = {\n",
    "            'db': vectorstore,\n",
    "            'retriever': retriever\n",
    "        }\n",
    "    return pdf_databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. LLM ì¶”ë¡ , ë‹µë³€ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    \"\"\"ìœ ë‹ˆì½”ë“œ ì •ê·œí™”\"\"\"\n",
    "    return unicodedata.normalize('NFC', s)\n",
    "\n",
    "def format_docs(docs):\n",
    "    # ë¬¸ì„œì˜ í˜ì´ì§€ ë‚´ìš©ì„ ì´ì–´ë¶™ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def generate_answers(df, pdf_databases, llm):\n",
    "    \"\"\"DataFrameì˜ ê° ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€ì„ ìƒì„±\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Answering Questions\"):\n",
    "        source = normalize_string(row['Source'])\n",
    "        question = row['Question']\n",
    "\n",
    "        # ì •ê·œí™”ëœ í‚¤ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰\n",
    "        normalized_keys = {normalize_string(k): v for k, v in pdf_databases.items()}\n",
    "        retriever = normalized_keys[source]['retriever']\n",
    "\n",
    "        # RAG ì²´ì¸ êµ¬ì„±\n",
    "        template = \"\"\"\n",
    "        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n",
    "        {context}\n",
    "\n",
    "        ì§ˆë¬¸: {question}\n",
    "        \n",
    "        ì£¼ì–´ì§„ ì§ˆë¬¸ì—ë§Œ ë‹µë³€í•˜ì„¸ìš”. ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ë‹µë³€í•  ë•Œ ì§ˆë¬¸ì˜ ì£¼ì–´ë¥¼ ì¨ì£¼ì„¸ìš”.\n",
    "        ë‹µë³€:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "        # # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        # prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        \n",
    "        rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "        # ë‹µë³€ ì¶”ë¡ \n",
    "        full_response = rag_chain.invoke(question)\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        results.append({\n",
    "            \"Source\": row['Source'],\n",
    "            \"Source_path\": row['Source_path'],\n",
    "            \"Question\": question,\n",
    "            \"Answer\": full_response\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 7. ìµœì¢… í†µí•© ë° ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-1. Vector DB ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  test_source\n"
     ]
    }
   ],
   "source": [
    "# google drive\n",
    "# !ls /content/drive/MyDrive/Contest/Dacon_Financial_Search/open/\n",
    "\n",
    "# local\n",
    "!ls ./open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05322df1a48d4011a344320c53a08f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7ff2ff0b6f47d981559ffe6b37a483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/179k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec7f52a605243848eef5105a21a377d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984ba1115b82417c9ba215bb58f20ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9329c63d95a47c0967e8cce9138a95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36a9f46afed145cc82356a91ef8db753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/418 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad66ace1809447eb1910d69177bff41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64be3194372447a99615c8e7be5d6ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ae32d52f3841e681603b20706582ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd11c2866374ca9a3df01d1ee241540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dee225e1aed745d0be45158a7b3ce373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/40.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d30c36443a4a8f8b528cf8767190c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae9e4cd11a947ffa88aa9718c50d143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0552c1904084d7e8dfb69f591ea97ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86abbf74fcbc4a6bba6caf44dee3b4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/852 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f17f22e1444c01a0d124d276c27ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadb880fc09f400a906bf558889a3624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bef909be7434fa5bd7ddc86dd740ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00010.safetensors:   0%|          | 0.00/1.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8291752e29f4d64955b8ebc46e3d152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b980f8fe444eb083a73a6a5b5b17b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d66b250e5a740928c1f181217e38e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95c36bdd83d426d8213e66b45fc2288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f822e7e72d549669e0dcc44b21c20e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078f5efdfaff40ce9064e4b2427406b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5963f5328b1403ebd1f2f3591a76f4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea31e5049ae4407dabbc177969c6c26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00010.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91419306328542a1b71f683542446f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00010.safetensors:   0%|          | 0.00/705M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11e91d075f641909bddb0bd258abd2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bb8dc99df445a3812edc966f8f2cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### [ model ] ####\n",
      "Gemma2ForCausalLM(\n",
      "  (model): Gemma2Model(\n",
      "    (embed_tokens): Embedding(256000, 3584, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-41): 42 x Gemma2DecoderLayer(\n",
      "        (self_attn): Gemma2SdpaAttention(\n",
      "          (q_proj): Linear(in_features=3584, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=3584, out_features=2048, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=3584, bias=False)\n",
      "          (rotary_emb): Gemma2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Gemma2MLP(\n",
      "          (gate_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "          (up_proj): Linear(in_features=3584, out_features=14336, bias=False)\n",
      "          (down_proj): Linear(in_features=14336, out_features=3584, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma2RMSNorm((3584,), eps=1e-06)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3584, out_features=256000, bias=False)\n",
      ")\n",
      "###################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# ì„ë² ë”© ëª¨ë¸ ì„¤ì •\n",
    "embeddings = setup_embeddings()\n",
    "llm = setup_llm_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing á„Œá…®á†¼á„‰á…©á„‡á…¦á†«á„á…¥á„€á…µá„‹á…¥á†¸á„‡á…®_á„’á…§á†¨á„‰á…µá†«á„á…¡á†¼á„‹á…¥á†¸á„‰á…¡á„‹á…¥á†¸á„’á…ªá„Œá…¡á„€á…³á†·(á„‹á…²á†¼á„Œá…¡)...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  11%|â–ˆ         | 1/9 [00:13<01:51, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing á„‡á…©á„€á…¥á†«á„‡á…©á†¨á„Œá…µá„‡á…®_á„‡á…®á„†á…©á„€á…³á†¸á„‹á…§(á„‹á…§á†¼á„‹á…¡á„‰á…®á„ƒá…¡á†¼) á„Œá…µá„‹á…¯á†«...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  22%|â–ˆâ–ˆâ–       | 2/9 [00:37<02:15, 19.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing á„‡á…©á„€á…¥á†«á„‡á…©á†¨á„Œá…µá„‡á…®_á„‚á…©á„‹á…µá†«á„Œá…¡á†¼á„€á…µá„‹á…­á„‹á…£á†¼á„‡á…©á„’á…¥á†· á„‰á…¡á„‹á…¥á†¸á„‹á…®á†«á„‹á…§á†¼...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  33%|â–ˆâ–ˆâ–ˆâ–      | 3/9 [01:08<02:28, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing á„‰á…¡á†«á„‹á…¥á†¸á„á…©á†¼á„‰á…¡á†¼á„Œá…¡á„‹á…¯á†«á„‡á…®_á„‹á…¦á„‚á…¥á„Œá…µá„‡á…¡á„‹á…®á„á…¥...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (8192). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Processing PDFs:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 4/9 [02:00<02:57, 35.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing á„€á…®á†¨á„á…©á„€á…­á„á…©á†¼á„‡á…®_á„’á…¢á†¼á„‡á…©á†¨á„Œá…®á„á…¢á†¨á„á…®á†¯á„Œá…¡...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 5/9 [02:37<02:23, 35.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS á„‹á…µá„‰á…² & á„‘á…©á„á…¥á„‰á…³ã€ 22-4á„’á…© ã€Šá„Œá…®á†¼á„‹á…¡á†¼-á„Œá…µá„‡á…¡á†¼ á„€á…¡á†« á„Œá…¢á„Œá…¥á†¼á„Œá…©á„Œá…¥á†¼á„Œá…¦á„ƒá…©ã€‹...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 6/9 [03:51<02:27, 49.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS á„‹á…µá„‰á…² & á„‘á…©á„á…¥á„‰á…³ã€ 23-2á„’á…© ã€Šá„’á…¢á†¨á„‰á…µá†·á„Œá…¢á„Œá…¥á†¼á„‰á…¡á„‹á…¥á†¸ á„‰á…¥á†¼á„€á…ªá„€á…ªá†«á„…á…µã€‹...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 7/9 [05:16<02:01, 60.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS á„‹á…µá„‰á…²&á„‘á…©á„á…¥á„‰á…³ã€ 22-2á„’á…© ã€Šá„Œá…¢á„Œá…¥á†¼á„‰á…¥á†¼á„€á…ªá„€á…ªá†«á„…á…µá„Œá…¦á„ƒá…©ã€‹...\n",
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 8/9 [06:29<01:04, 64.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ã€ŒFIS á„‹á…µá„‰á…² & á„‘á…©á„á…¥á„‰á…³ã€(á„‰á…µá†«á„€á…²) á„á…©á†¼á„€á…¯á†« á„Œá…¦1á„’á…© ã€Šá„‹á…®á„‡á…¡á†¯á„‡á…®á„á…¢ã€‹...\n",
      "--Generated 4 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Generated 1 clusters--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [11:28<00:00, 76.52s/it] \n"
     ]
    }
   ],
   "source": [
    "# PDF íŒŒì¼ë“¤ ì²˜ë¦¬ ë° ë²¡í„° DB ìƒì„±\n",
    "\n",
    "# google drive\n",
    "# base_directory = r'/content/drive/MyDrive/Contest/Dacon_Financial_Search/open' # pdf source ê²½ë¡œ\n",
    "# df = pd.read_csv(r'/content/drive/MyDrive/Contest/Dacon_Financial_Search/open/test.csv') # csv íŒŒì¼ ê²½ë¡œ\n",
    "\n",
    "# runpods\n",
    "base_directory = f'./open' # pdf source ê²½ë¡œ\n",
    "df = pd.read_csv(f'{base_directory}/test.csv') # csv íŒŒì¼ ê²½ë¡œ\n",
    "pdf_databases = process_pdfs_from_dataframe(df, base_directory, embeddings, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-2. ì¶”ë¡  ì‹¤í–‰, ë‹µë³€ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your LangChain API key:  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Answering Questions: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98/98 [18:36<00:00, 11.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# Langsmith ì„¤ì •\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •, ì½œì†”ì— Langchain Api Key ì…ë ¥\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(prompt=\"Enter your LangChain API key: \")\n",
    "\n",
    "# ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\n",
    "results = generate_answers(df, pdf_databases, llm) # list ë°˜í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. ì œì¶œìš© íŒŒì¼ ìƒì„± ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œì¶œ ìƒ˜í”Œ íŒŒì¼ ë¡œë“œ\n",
    "submit_df = pd.read_csv(f\"./open/sample_submission.csv\")\n",
    "\n",
    "# ìƒì„±ëœ ë‹µë³€ì„ ì œì¶œ DataFrameì— ì¶”ê°€\n",
    "submit_df['Answer'] = [item['Answer'] for item in results]\n",
    "submit_df['Answer'] = submit_df['Answer'].fillna(\"ë°ì´ì½˜\") # ëª¨ë¸ì—ì„œ ë¹ˆ ê°’ (NaN) ìƒì„± ì‹œ ì±„ì ì— ì˜¤ë¥˜ê°€ ë‚  ìˆ˜ ìˆìŒ [ ì£¼ì˜ ]\n",
    "\n",
    "# ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "submit_df.to_csv(\"./rag_raptor_submission.csv\", encoding='UTF-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
